# GenerativeModel-HMM implementation
#
#
SHELL=/bin/bash
PYTHON=python

SRC=src
BIN=bin
DATA_tmp=data
MODELS_tmp=models
LOG=log
nepochs=
nclasses=
nfeats=

DATA=$(DATA_tmp)/$(nfeats)feats
MODELS=$(MODELS_tmp)/$(nfeats)feats
MODELS_INTERM=$(shell echo $(MODELS)/epoch{1..$(nepochs)}.mdl)

training_data=$(DATA)/train$(nfeats).pkl
testing_data=$(DATA)/test$(nfeats).pkl

all: train

init:
	mkdir -p $(MODELS) $(LOG) $(DATA)


prepare_data: $(training_data) $(testing_data)
	$(PYTHON) $(BIN)/prepare_data.py $(nclasses) $^

train: 
	for i in $(MODELS_INTERM); do \
		$(MAKE) -f Makefile_run -j 6 -s $$i; \
		sleep 2;\
	done
#	echo "Done" > $^


$(MODELS)/%.mdl:
	$(PYTHON) $(BIN)/aggregate_models.py $@
	$(PYTHON) -m cProfile -o log/acc_profile.txt $(BIN)/compute_accuracy.py $@ $(training_data) $(testing_data)  >> $(LOG)/class_all.log


$(MODELS)/%.mdlc:
	$(eval logfile=$(LOG)/`basename $@ | sed -e 's/^.*\(class\)/\1/g' -e 's/.mdlc/.log'/g`)
	echo `date` ":" $(PYTHON) $(BIN)/train_class.py $(training_data) $@ >> $(logfile)
	$(PYTHON) $(BIN)/train_class.py $(training_data) $@ >> $(logfile)

watch:
	tail -f $(LOG)/class*.log

clean:
	rm -f $(DATA)/train*_*.pkl
	rm -f $(DATA)/test*_*.pkl 
	rm -f $(DATA)/class_map.json
	rm -f $(MODELS)/epoch*.mdl 
	rm -f $(MODELS)/epoch*_class*.mdlc
	rm -f $(LOG)/class*.log
	rm -f Makefile_run


.SECONDARY: 

.PRECIOUS:
