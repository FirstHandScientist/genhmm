# GenerativeModel-HMM implementation
#
#
SHELL=/bin/bash
PYTHON=python

SRC=src
BIN=bin
DATA_tmp=data
MODELS_tmp=models
LOG=log
nepochs=
nclasses=
nfeats=

DATA=$(nfeats)feats/data
MODELS=$(nfeats)feats/models
LOG=$(nfeats)feats/log
MODELS_INTERM=$(shell echo $(MODELS)/epoch{1..$(nepochs)}.mdl)

training_data=$(DATA)/train.$(nfeats).pkl
testing_data=$(DATA)/test.$(nfeats).pkl

all: train

init:
	mkdir -p $(MODELS) $(LOG) $(DATA)


prepare_data: $(training_data) $(testing_data)
	$(PYTHON) $(BIN)/prepare_data.py $(nclasses) $^

train: 
	for i in $(MODELS_INTERM); do \
		if [[ `echo $${i%.*}_class* | wc -w` != $(nclasses) ]]; then rm -f $$i; fi; \
		$(MAKE) -f Makefile_run -j 2 -s $$i; \
		sleep 2;\
	done
#	echo "Done" > $^


$(MODELS)/%.mdl:
	$(PYTHON) $(BIN)/aggregate_models.py $@

$(LOG)/%.acc:
	$(PYTHON) $(BIN)/aggregate_accuracy.py $^ >> $(LOG)/class_all.log


$(MODELS)/%.mdlc:
	$(eval logfile=$(LOG)/`basename $@ | sed -e 's/^.*\(class\)/\1/g' -e 's/.mdlc/.log'/g`)
	echo `date` ":" $(PYTHON) $(BIN)/train_class_gaus.py $(training_data) $@ >> $(logfile)
	$(PYTHON) $(BIN)/train_class_gaus.py $(training_data) $@ >> $(logfile)

$(LOG)/%.accc:
	$(PYTHON) $(BIN)/compute_accuracy_class.py $* $(training_data) $(testing_data) $(MODELS) >> $@

watch:
	tail -f $(LOG)/class*.log

clean:
	rm -f $(DATA)/train*_*.pkl
	rm -f $(DATA)/test*_*.pkl 
	rm -f $(DATA)/class_map.json
	rm -f $(MODELS)/epoch*.mdl 
	rm -f $(MODELS)/epoch*_class*.mdlc
	rm -f $(LOG)/class*.log
	rm -f Makefile_run


.SECONDARY: 

.PRECIOUS:
